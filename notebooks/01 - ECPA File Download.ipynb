{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WalterPaixaoCortes/r3s-scripts/blob/main/notebooks/Data_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYUysU-5pPrt"
      },
      "source": [
        "# ECPA file download"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQ9zNqnFwMz"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hem7KqcEnEo1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import zipfile\n",
        "import gzip\n",
        "import traceback\n",
        "import glob\n",
        "import logging\n",
        "import sys\n",
        "\n",
        "from logging.handlers import TimedRotatingFileHandler\n",
        "from urllib.parse import urlparse\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import requests as r\n",
        "\n",
        "from bs4 import BeautifulSoup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the parameters for execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "create_folders = False\n",
        "download_files = False\n",
        "unzip_files = False"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzhDfwfZ5Wxm"
      },
      "source": [
        "## Defining the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Load Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "fhandler = TimedRotatingFileHandler(\"logs/epa_download.log\", when=\"midnight\", interval=1)\n",
        "fhandler.suffix = \"%Y%m%d\"\n",
        "logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "        handlers=[fhandler, logging.StreamHandler(sys.stdout)],\n",
        "    )\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Build download URLS list"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ap9_fWGwpq4j"
      },
      "outputs": [],
      "source": [
        "download_urls = [\"https://echo.epa.gov/files/echodownloads/frs_downloads.zip\",\n",
        "                 \"https://echo.epa.gov/files/echodownloads/case_downloads.zip\", \n",
        "                 \"https://echo.epa.gov/files/echodownloads/npdes_downloads.zip\",\n",
        "                 \"https://echo.epa.gov/files/echodownloads/npdes_eff_downloads.zip\",\n",
        "                 \"https://echo.epa.gov/files/echodownloads/npdes_master_general_permits.zip\",\n",
        "                 \"https://echo.epa.gov/files/echodownloads/npdes_outfalls_layer.zip\",\n",
        "                 \"https://echo.epa.gov/files/echodownloads/npdes_limits.zip\",\n",
        "                 \"https://echo.epa.gov/files/echodownloads/SDWA_latest_downloads.zip\"]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For TRI files, we need to add a sequence of files, since 1987."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "tri_start = 1987\n",
        "tri_end = datetime.datetime.now().year -1\n",
        "tri_end_url = \"https://www3.epa.gov/tri/pds/US_%s.zip\"\n",
        "tri_url = \"https://www3.epa.gov/tri/current/US_%s.zip\"\n",
        "\n",
        "logger.info(f\"Loading URLs for TRI downloads from {tri_start} to {tri_end}...\")\n",
        "year = tri_start\n",
        "while year <= tri_end:\n",
        "  if year == tri_end:\n",
        "    url = tri_end_url % year\n",
        "  else:\n",
        "    url = tri_url % year\n",
        "  \n",
        "  download_urls.append(url)\n",
        "  year += 1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For WQI files, we need to detect the correct files on the folder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_wqi_url = \"https://echo.epa.gov/files/echodownloads/Data-Analytics/WQI\"\n",
        "\n",
        "logger.info(f\"Loading URLs for WQI downloads...\")\n",
        "response = r.get(base_wqi_url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "links = soup.find_all('a')\n",
        "\n",
        "for item in links:\n",
        "  if \"ResultFileToEnd2Output\" in item[\"href\"]:\n",
        "    download_urls.append(f'{base_wqi_url}/{item[\"href\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "There is a special routine for DMR files as well."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "base_dmr_url = \"https://echo.epa.gov/files/echodownloads\"\n",
        "\n",
        "logger.info(f\"Loading URLs for DMR downloads...\")\n",
        "response = r.get(base_dmr_url)\n",
        "soup = BeautifulSoup(response.content, 'html.parser')\n",
        "links = soup.find_all('a')\n",
        "\n",
        "for item in links:\n",
        "  if \"npdes_dmrs_\" in item[\"href\"]:\n",
        "    download_urls.append(f'{base_dmr_url}/{item[\"href\"]}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "zipfile_folder = \"zipfiles\"\n",
        "unzipped_folder = \"rawfiles\"\n",
        "database_folder = \"database\"\n",
        "extension = \".zip\"\n",
        "\n",
        "allowed_extensions = [\".txt\",\".csv\"]\n",
        "\n",
        "my_conn = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Now, to help us out to not download files that were already downloaded, lets generate a list of downloaded files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "downloaded_files = []\n",
        "for item in os.listdir(zipfile_folder):\n",
        "  downloaded_files.append(os.path.basename(urlparse(item).path))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JCdaeWamFsTX"
      },
      "source": [
        "## Defining the environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_MXVLFcaE7sD",
        "outputId": "4b59d7b9-e1da-4792-9b77-e626bd67a320"
      },
      "outputs": [],
      "source": [
        "if create_folders:\n",
        "  if not os.path.exists(zipfile_folder): \n",
        "    os.mkdir(zipfile_folder)\n",
        "  if not os.path.exists(unzipped_folder): \n",
        "    os.mkdir(unzipped_folder)\n",
        "  if not os.path.exists(database_folder): \n",
        "    os.mkdir(database_folder)\n",
        "else:\n",
        "  logger.info(\"Folders already created...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XRrvb3U21_lq"
      },
      "source": [
        "## Download zip files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TvysEExu1zsp",
        "outputId": "aec3bbec-d75c-4784-f252-779f41b6df47"
      },
      "outputs": [],
      "source": [
        "if download_files:\n",
        "  logger.info(f\"Starting download process. Total files to be downloaded: {len(download_urls)}...\")\n",
        "  for download_url in download_urls:\n",
        "    file_name = os.path.basename(urlparse(download_url).path)\n",
        "    table_name, ext =  os.path.splitext(file_name)\n",
        "    if file_name not in downloaded_files:\n",
        "      logger.info(f\"Downloading file {file_name}...\")\n",
        "      try:\n",
        "        response = r.get(download_url, allow_redirects=True)\n",
        "        with open(os.path.join(zipfile_folder, file_name), \"wb\") as fw:\n",
        "          fw.write(response.content)\n",
        "          logger.info(f\"--> File {file_name} saved.\")\n",
        "      except:\n",
        "          logger.error(f\"--> File {file_name} not downloaded.\")\n",
        "else:\n",
        "  logger.info(\"Files already downloaded...\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y24JS1_z2yC3"
      },
      "source": [
        "## Unzip the files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oh4q-wLe27qR",
        "outputId": "401fbb8c-9528-4d7f-c0e8-e2e9dbc8d383"
      },
      "outputs": [],
      "source": [
        "if unzip_files:\n",
        "  for item in os.listdir(zipfile_folder):\n",
        "    if item.endswith(extension) and item not in downloaded_files: \n",
        "      logger.info(f\"Unzipping file {item}...\")\n",
        "      try:\n",
        "        file_name = os.path.abspath(os.path.join(zipfile_folder, item)) \n",
        "        zip_ref = zipfile.ZipFile(file_name)\n",
        "        zip_ref.extractall(unzipped_folder)\n",
        "        zip_ref.close()\n",
        "        logger.info(f\"--> File {item} unzipped.\")\n",
        "      except:\n",
        "        logger.error(f\"--> File {item} not unzipped.\")\n",
        "    elif item.endswith(\".gz\")  and item not in downloaded_files:\n",
        "      logger.info(f\"Decompressing file {item}...\")\n",
        "      try:\n",
        "        file_name = os.path.abspath(os.path.join(zipfile_folder, item)) \n",
        "        new_file_name = os.path.abspath(os.path.join(unzipped_folder, item.replace(\".gz\",\"\"))) \n",
        "        file_out = gzip.decompress(open(file_name, 'rb').read())\n",
        "        with open(new_file_name, 'wb') as fw:\n",
        "          fw.write(file_out)\n",
        "        logger.info(f\"File {new_file_name} decompressed and saved...\")        \n",
        "      except:\n",
        "        logger.error(f\"--> File {item} not decompressed.\")\n",
        "    else:\n",
        "      logger.info(f\"Skipping file {item}.\")\n",
        "else:\n",
        "  logger.info(\"Files already unzipped...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Removing files not used"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "logger.info(\"Preparing list of files to be processed...\")\n",
        "list_of_files = filter(os.path.isfile, glob.glob(unzipped_folder + '/*') )\n",
        "files = [os.path.basename(item) for item in list_of_files]\n",
        "\n",
        "for item in files:\n",
        "  table_name, file_ext = os.path.splitext(os.path.basename(item))\n",
        "  if table_name.lower() not in os.getenv('USED_SOURCE'):\n",
        "    os.remove(os.path.join(unzipped_folder, item))\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Data Exploration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "2699b20de84054a0debfded0092f82ecde8069d2acfd0beccd8a223bb7c57c3a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
