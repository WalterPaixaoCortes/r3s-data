{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/WalterPaixaoCortes/r3s-scripts/blob/main/notebooks/Data_Exploration.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SYUysU-5pPrt"
      },
      "source": [
        "# Validate Source Database Load"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LTQ9zNqnFwMz"
      },
      "source": [
        "## Importing libraries"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hem7KqcEnEo1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import traceback\n",
        "import glob\n",
        "import gc\n",
        "import logging\n",
        "import sqlite3\n",
        "import sys\n",
        "\n",
        "from sqlalchemy import event\n",
        "from sqlalchemy import create_engine\n",
        "from logging.handlers import TimedRotatingFileHandler\n",
        "from dotenv import load_dotenv\n",
        "\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Declaring auxiliary functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [],
      "source": [
        "def count_lines(file_name):\n",
        "    fp = open(file_name,'r', encoding=\"iso-8859-1\")\n",
        "    for line_count, line in enumerate(fp):\n",
        "        pass\n",
        "    return line_count\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Load Environment Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 3,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "load_dotenv()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Defining the parameters for execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [],
      "source": [
        "use_sqlite = eval(os.getenv('USE_SQLITE3'))\n",
        "used_source = eval(os.getenv('USED_SOURCE'))\n",
        "validate_process = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SzhDfwfZ5Wxm"
      },
      "source": [
        "## Defining the variables"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing Logger"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "fhandler = TimedRotatingFileHandler(\"logs/validate_source_db_load.log\", when=\"midnight\", interval=1)\n",
        "fhandler.suffix = \"%Y%m%d\"\n",
        "logging.basicConfig(\n",
        "        level=logging.INFO,\n",
        "        format=\"%(asctime)s - %(levelname)s - %(message)s\",\n",
        "        handlers=[fhandler, logging.StreamHandler(sys.stdout)],\n",
        "    )\n",
        "logger = logging.getLogger(__name__)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Initializing Variables"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "unzipped_folder = \"rawfiles\"\n",
        "database_folder = \"database\"\n",
        "extension = \".zip\"\n",
        "\n",
        "allowed_extensions = [\".txt\",\".csv\"]\n",
        "database_name = f\"{database_folder}/source.db\"\n",
        "\n",
        "my_conn = None"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Connecting or Creating database"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-11 08:33:35,944 - INFO - postgresql+psycopg2://postgres:u9hnRW!TcCbqo2j@r3-tableau.cluster-cs2ga4wck7ra.us-east-2.rds.amazonaws.com/postgres\n",
            "2022-10-11 08:33:36,051 - INFO - Connected to database...\n"
          ]
        }
      ],
      "source": [
        "my_conn = None\n",
        "if use_sqlite:\n",
        "  my_conn=sqlite3.connect(database_name)\n",
        "else:\n",
        "  logger.info(os.getenv(\"PG_DATA_CONN\"))\n",
        "  my_conn = create_engine(os.getenv(\"PG_DATA_CONN\"))  \n",
        "logger.info(\"Connected to database...\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Validating Load Process"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Here we will check based on line counts if the process to send to the database was sucessful or not."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2022-10-11 08:33:36,128 - INFO - Preparing list of files to be processed...\n",
            "2022-10-11 08:33:36,148 - INFO - rawfiles\\wifia_loans_closed.csv and wifia_loans_closed being compared...\n",
            "2022-10-11 08:33:40,834 - INFO - rawfiles\\wifia_projects_selected.csv and wifia_projects_selected being compared...\n",
            "2022-10-11 08:33:41,449 - INFO - rawfiles\\wifia_letters_submitted.csv and wifia_letters_submitted being compared...\n",
            "2022-10-11 08:33:42,019 - INFO - rawfiles\\EPA_INFORMAL_ENFORCEMENT_ACTIONS.csv and EPA_INFORMAL_ENFORCEMENT_ACTIONS being compared...\n",
            "2022-10-11 08:33:42,780 - INFO - rawfiles\\CASE_ENFORCEMENT_CONCLUSION_SEP.csv and CASE_ENFORCEMENT_CONCLUSION_SEP being compared...\n",
            "2022-10-11 08:33:43,519 - INFO - rawfiles\\CASE_RELATED_ACTIVITIES.csv and CASE_RELATED_ACTIVITIES being compared...\n",
            "2022-10-11 08:33:44,119 - INFO - rawfiles\\CASE_RELIEF_SOUGHT.csv and CASE_RELIEF_SOUGHT being compared...\n",
            "2022-10-11 08:33:44,725 - INFO - rawfiles\\CASE_POLLUTANTS.csv and CASE_POLLUTANTS being compared...\n",
            "2022-10-11 08:33:45,749 - INFO - rawfiles\\CASE_PENALTIES.csv and CASE_PENALTIES being compared...\n",
            "2022-10-11 08:33:46,876 - INFO - rawfiles\\NPDES_NAICS.csv and NPDES_NAICS being compared...\n",
            "2022-10-11 08:33:47,921 - INFO - rawfiles\\CASE_ENFORCEMENT_CONCLUSION_DOLLARS.csv and CASE_ENFORCEMENT_CONCLUSION_DOLLARS being compared...\n",
            "2022-10-11 08:33:48,899 - INFO - rawfiles\\CASE_VIOLATIONS.csv and CASE_VIOLATIONS being compared...\n",
            "2022-10-11 08:33:49,845 - INFO - rawfiles\\CASE_ENFORCEMENT_CONCLUSION_POLLUTANTS.csv and CASE_ENFORCEMENT_CONCLUSION_POLLUTANTS being compared...\n",
            "2022-10-11 08:33:51,219 - INFO - rawfiles\\CASE_ENFORCEMENT_TYPE.csv and CASE_ENFORCEMENT_TYPE being compared...\n",
            "2022-10-11 08:33:52,820 - INFO - rawfiles\\CASE_DEFENDANTS.csv and CASE_DEFENDANTS being compared...\n",
            "2022-10-11 08:33:54,321 - INFO - rawfiles\\NPDES_FORMAL_ENFORCEMENT_ACTIONS.csv and NPDES_FORMAL_ENFORCEMENT_ACTIONS being compared...\n",
            "2022-10-11 08:33:55,819 - INFO - rawfiles\\CASE_LAW_SECTIONS.csv and CASE_LAW_SECTIONS being compared...\n",
            "2022-10-11 08:33:57,427 - INFO - rawfiles\\CASE_ENFORCEMENT_CONCLUSIONS.csv and CASE_ENFORCEMENT_CONCLUSIONS being compared...\n",
            "2022-10-11 08:33:58,220 - INFO - rawfiles\\NPDES_SICS.csv and NPDES_SICS being compared...\n",
            "2022-10-11 08:33:59,776 - INFO - rawfiles\\CASE_FACILITIES.csv and CASE_FACILITIES being compared...\n",
            "2022-10-11 08:34:01,621 - INFO - rawfiles\\CASE_ENFORCEMENT_CONCLUSION_COMPLYING_ACTIONS.csv and CASE_ENFORCEMENT_CONCLUSION_COMPLYING_ACTIONS being compared...\n",
            "2022-10-11 08:34:03,019 - INFO - rawfiles\\CASE_PROGRAMS.csv and CASE_PROGRAMS being compared...\n",
            "2022-10-11 08:34:04,919 - INFO - rawfiles\\FRS_SIC_CODES.csv and FRS_SIC_CODES being compared...\n",
            "2022-10-11 08:34:07,219 - INFO - rawfiles\\FRS_NAICS_CODES.csv and FRS_NAICS_CODES being compared...\n",
            "2022-10-11 08:34:08,790 - INFO - rawfiles\\CASE_ENFORCEMENTS.csv and CASE_ENFORCEMENTS being compared...\n",
            "2022-10-11 08:34:10,208 - INFO - rawfiles\\NPDES_INFORMAL_ENFORCEMENT_ACTIONS.csv and NPDES_INFORMAL_ENFORCEMENT_ACTIONS being compared...\n",
            "2022-10-11 08:34:11,306 - INFO - rawfiles\\FRS_FACILITIES.csv and FRS_FACILITIES being compared...\n",
            "2022-10-11 08:34:13,909 - INFO - rawfiles\\FRS_PROGRAM_LINKS.csv and FRS_PROGRAM_LINKS being compared...\n",
            "2022-10-11 08:34:19,644 - INFO - Saving results as files...\n"
          ]
        }
      ],
      "source": [
        "if validate_process:\n",
        "  success_data = { \"File\": [], \"File Lines\": [], \"Table\": [], \"Table Rows\": [], \"Difference\": []}\n",
        "  error_data = { \"File\": [], \"File Lines\": [], \"Table\": [], \"Table Rows\": [], \"Difference\": []}\n",
        "\n",
        "  logger.info(\"Preparing list of files to be processed...\")\n",
        "  list_of_files = filter(os.path.isfile, glob.glob(unzipped_folder + '/*') )\n",
        "  list_of_files = sorted(list_of_files, key =  lambda x: os.stat(x).st_size)  \n",
        "  files = [os.path.basename(item) for item in list_of_files]\n",
        "  for item in files:\n",
        "    try:\n",
        "      file_name = os.path.join(unzipped_folder, item)\n",
        "      table_name, file_ext = os.path.splitext(os.path.basename(item))\n",
        "      logger.info(f\"{file_name} and {table_name} being compared...\")\n",
        "      if file_ext in allowed_extensions and table_name.lower() in used_source:\n",
        "        file_count = count_lines(file_name)\n",
        "\n",
        "        db_count = 0\n",
        "        if use_sqlite:\n",
        "          db_count = my_conn.execute(f\"select count(*) from {table_name.lower()}\").fetchone()[0]\n",
        "        else:\n",
        "          db_count = my_conn.execute(f\"select count(*) from source.{table_name.lower()}\").fetchone()[0]\n",
        "\n",
        "        diff = file_count - db_count\n",
        "        if diff > 0:\n",
        "          error_data[\"File\"].append(file_name)\n",
        "          error_data[\"File Lines\"].append(file_count)\n",
        "          error_data[\"Table\"].append(table_name)\n",
        "          error_data[\"Table Rows\"].append(db_count)\n",
        "          error_data[\"Difference\"].append(diff)\n",
        "        else:\n",
        "          success_data[\"File\"].append(file_name)\n",
        "          success_data[\"File Lines\"].append(file_count)\n",
        "          success_data[\"Table\"].append(table_name)\n",
        "          success_data[\"Table Rows\"].append(db_count)\n",
        "          success_data[\"Difference\"].append(diff)\n",
        "    except:\n",
        "        logger.error(traceback.format_exc())\n",
        "\n",
        "  logger.info(\"Saving results as files...\")\n",
        "  error_report = pd.DataFrame(error_data)\n",
        "  error_report.to_markdown(os.path.join(database_folder, \"issues.md\"))\n",
        "\n",
        "  success_report = pd.DataFrame(success_data)\n",
        "  success_report.to_markdown(os.path.join(database_folder, \"success.md\"))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Closing the Database Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "id": "9-W2GCRhv0xE",
        "outputId": "cf40c9c8-b8ad-433c-888d-26a1dd56574c"
      },
      "outputs": [],
      "source": [
        "if use_sqlite:\n",
        "  my_conn.close()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "include_colab_link": true,
      "name": "Data Exploration.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.9.6 ('venv': venv)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "vscode": {
      "interpreter": {
        "hash": "2699b20de84054a0debfded0092f82ecde8069d2acfd0beccd8a223bb7c57c3a"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
